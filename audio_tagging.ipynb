{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import audio_tagging_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Keras and other pre-processing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "\n",
    "# This is needed to get if the gpu is detected, as we carried out runs on our local machines.\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "MSjOU2eBbUyR"
   },
   "outputs": [],
   "source": [
    "A CNN within our project will be fed the spectrograms of the .wav as input images. Such images need to be generated first, this is carried out by calling a method defined in the utility file. Such method will fetch each .wav present in the input directory and traspose it to its corresponding spectrogram, saving it as a .jpg image. The project relied a lot on os.path.join as to make paths os agnostic.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join('images', 'train')\n",
    "test_path = os.path.join('images', 'test')\n",
    "\n",
    "if not os.path.exists('runs'):\n",
    "    os.mkdir('runs')\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.mkdir(train_path)\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    os.mkdir(test_path)\n",
    "\n",
    "if not len(glob(os.path.join(train_path, '*'))) == 9473:\n",
    "    utils.create_images('train', 'train')\n",
    "\n",
    "if not len(glob(os.path.join(test_path, '*'))) == 1600:\n",
    "    utils.create_images('test', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "dbMBfAgQJNTD"
   },
   "outputs": [],
   "source": [
    "As the code aim to be highly modular, each employed model is defined as a method, this makes the Notebook more organic and readable, as each model is encapsulated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, LeakyReLU, Conv2D, MaxPooling2D, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "number_of_classes = 41\n",
    "\n",
    "def spectrogram_2d_conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(model_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x) #TO-FIX THIS\n",
    "\n",
    "    model = Model(model_input, x, name='spectrogram_2d_conv_pool_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def kaggle_2d_conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(model_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='kaggle_2d_conv_pool_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def kaggle_1d_conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    x = Conv1D(16, 9, activation='relu', padding=\"valid\")(model_input)\n",
    "    x = Conv1D(16, 9, activation='relu', padding=\"valid\")(x)\n",
    "    x = MaxPooling1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Conv1D(256, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = Conv1D(256, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1028, activation='relu')(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='kaggle_1d_conv_pool_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn_lstm(model_input: Tensor) -> training.Model:\n",
    "    x = LSTM(512, activation='relu')(model_input)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='lstm')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Now it is time to set up our trainining and evaluation pipeline for the model employing the .jpg spectrograms. The pipeline implement Kfold validation during training and evaluate each model on the test set, as well as generating its predictions using the best model obtained, as the best weights are saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Model: \"spectrogram_2d_conv_pool_cnn\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 64, 64, 32)        896       \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 62, 62, 64)        18496     \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n_________________________________________________________________\ndropout (Dropout)            (None, 31, 31, 64)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 31, 31, 64)        36928     \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 29, 29, 64)        36928     \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n_________________________________________________________________\ndropout_1 (Dropout)          (None, 14, 14, 64)        0         \n_________________________________________________________________\nconv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n_________________________________________________________________\nconv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n_________________________________________________________________\ndropout_2 (Dropout)          (None, 6, 6, 128)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 4608)              0         \n_________________________________________________________________\ndense (Dense)                (None, 512)               2359808   \n_________________________________________________________________\ndropout_3 (Dropout)          (None, 512)               0         \n_________________________________________________________________\ndense_1 (Dense)              (None, 41)                21033     \n=================================================================\nTotal params: 2,695,529\nTrainable params: 2,695,529\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "number_of_splits = 5\n",
    "\n",
    "# Shape of the input to the CNN, this shape is obtained from the flow_from_dataset method implemented in the next cell.\n",
    "model_input = Input(shape=(64, 64, 3))\n",
    "spectrogram_2d_conv_pool_cnn = spectrogram_2d_conv_pool_cnn(model_input)\n",
    "spectrogram_2d_conv_pool_cnn.compile(optimizers.Adam(0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "spectrogram_2d_conv_pool_cnn.summary()\n",
    "\n",
    "# We generate a folder for each model, this allows for a clear separation of the runs. Allowing for a cleaner folder structure.\n",
    "\n",
    "run_dir = os.path.join('runs', spectrogram_2d_conv_pool_cnn.name)\n",
    "if not os.path.exists(run_dir):\n",
    "    os.mkdir(run_dir)\n",
    "if os.path.exists(os.path.join(run_dir, 'logs')):\n",
    "    shutil.rmtree(os.path.join(run_dir, 'logs'))\n",
    "    \n",
    "traindf_dir = os.path.join('meta', 'train.csv')\n",
    "testdf_dir = os.path.join('meta', 'test.csv')\n",
    "traindf=pd.read_csv(traindf_dir)\n",
    "testdf=pd.read_csv(testdf_dir)    \n",
    "\n",
    "# As the datasets have .wav, they need to be modified to search for .jpg files\n",
    "traindf[\"fname\"]= traindf[\"fname\"].apply(utils.append_ext)\n",
    "testdf[\"fname\"]= testdf[\"fname\"].apply(utils.append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training con_pool_cnn\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "# The class indices to encode the labels need to be static(if not, ensemble of predictiosn will not be correct)\n",
    "class_indices = {}\n",
    "\n",
    "kfold_validation = KFold(n_splits= number_of_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# This structure is based on the one followed by the Kaggle notebook: https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data\n",
    "#Using random_state = 42 for repeatibility\n",
    "print(f'+-----------Training {spectrogram_2d_conv_pool_cnn.name} Model-----------+')\n",
    "for i, (train_split_indexes, test_split_indexes) in enumerate(kfold_validation.split(traindf)):\n",
    "    train_fold = traindf.iloc[train_split_indexes]\n",
    "    val_fold = traindf.iloc[test_split_indexes]\n",
    "\n",
    "    best_weights_file = os.path.join(run_dir, f'best_{i}.h5')\n",
    "    checkpoint = ModelCheckpoint(best_weights_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir= os.path.join(run_dir, 'logs', f'fold_{i}'), write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "\n",
    "    # flow_from_dataframe is useful as it generates the bitstreams to pass to the model give the image folder and reference dataframe\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=train_fold,\n",
    "        directory=os.path.join('images', 'train'),\n",
    "        x_col=\"fname\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    valid_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=val_fold,\n",
    "        directory=os.path.join('images', 'train'),\n",
    "        x_col=\"fname\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "    spectrogram_2d_conv_pool_cnn.fit(train_generator,\n",
    "                    callbacks=callbacks_list,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=1)\n",
    "\n",
    "    spectrogram_2d_conv_pool_cnn.load_weights(best_weights_file)\n",
    "    \n",
    "    train_generator.reset()\n",
    "    valid_generator.reset()\n",
    "    \n",
    "    eval_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=testdf,\n",
    "        directory=os.path.join('images', 'test'),\n",
    "        x_col=\"fname\",\n",
    "        y_col= \"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    STEP_SIZE_EVAL=eval_generator.n//eval_generator.batch_size\n",
    "\n",
    "    # It is important to reset the generator before evaluation\n",
    "    eval_generator.reset()\n",
    "    \n",
    "    spectrogram_2d_conv_pool_cnn.evaluate(eval_generator, steps=STEP_SIZE_EVAL, verbose= 1)\n",
    "    \n",
    "    test_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=testdf,\n",
    "        directory=os.path.join('images', 'test'),\n",
    "        x_col=\"fname\",\n",
    "        y_col= None,\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        class_mode= None,\n",
    "        target_size=(64,64))\n",
    "    \n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    \n",
    "    pred = spectrogram_2d_conv_pool_cnn.predict(test_generator, steps=STEP_SIZE_TEST, verbose= 1)\n",
    "    \n",
    "    np.save(os.path.join(run_dir, f'test_predictions_{i}.npy'), pred)\n",
    "    \n",
    "    pd.DataFrame(spectrogram_2d_conv_pool_cnn.history.history).plot()\n",
    "    \n",
    "    #On last step, retrieve actual class_indices, this is used to retrieve the actual string labels\n",
    "    if i == number_of_splits - 1:\n",
    "        class_indices = train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#Ensembling of the predictions using geometric average\n",
    "pred_list = []\n",
    "for i in range(number_of_splits):\n",
    "    pred_list.append(np.load(os.path.join(run_dir, f'test_predictions_{i}.npy')))\n",
    "\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "\n",
    "#Saving predictions\n",
    "predicted_class_indices = np.argmax(prediction,axis=-1)\n",
    "\n",
    "#Classes need to be retrieved using the class_indices used by the train generators, for simplicity, the class indices will be used to the other two models.\n",
    "labels = dict((v,k) for k,v in class_indices.items())\n",
    "predicted_labels = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "test = pd.read_csv(testdf_dir)\n",
    "\n",
    "test[['fname', 'label']].to_csv(os.path.join(run_dir, f'{spectrogram_2d_conv_pool_cnn.name}_predictions.csv'), index=False)\n",
    "\n",
    "y_true = test['label']\n",
    "y_pred = predicted_labels\n",
    "\n",
    "print(f'+-----------Printing {spectrogram_2d_conv_pool_cnn.name} predictions evaluations-----------+')\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {
    "colab_type": "text",
    "id": "D8cFBm1fJFe5"
   },
   "outputs": [],
   "source": [
    "Now we will train a different model that uses raw mfcc obtained from the .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 2\n",
    "n_mfcc = 40\n",
    "\n",
    "#raw .wav and mfcc are obtained using different sample rates, we followed the values used on the Kaggle notebook previously cited.\n",
    "kaggle_2d_sr = 44100\n",
    "kaggle_1d_sr = 16000\n",
    "\n",
    "kaggle_2d_seed = 2\n",
    "kaggle_1d_seed = 1\n",
    "\n",
    "model_input = Input(shape=utils.mfcc_input_sizes(n_mfcc, kaggle_2d_sr, max_len))\n",
    "kaggle_2d_conv_pool_cnn = kaggle_2d_conv_pool_cnn(model_input) \n",
    "kaggle_2d_conv_pool_cnn.compile(optimizers.Adam(0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "model_input = Input(shape=utils.wav_input_sizes(kaggle_1d_sr, max_len))\n",
    "kaggle_1d_conv_pool_cnn = kaggle_1d_conv_pool_cnn(model_input) \n",
    "kaggle_1d_conv_pool_cnn.compile(optimizers.Adam(0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "kaggle_1d_run_dir = os.path.join('runs', kaggle_1d_conv_pool_cnn.name)\n",
    "\n",
    "if not os.path.exists(kaggle_1d_run_dir):\n",
    "    os.mkdir(kaggle_1d_run_dir)\n",
    "if os.path.exists(os.path.join(kaggle_1d_run_dir, 'logs')):\n",
    "    shutil.rmtree(os.path.join(kaggle_1d_run_dir, 'logs'))\n",
    "    \n",
    "kaggle_2d_run_dir = os.path.join('runs', kaggle_2d_conv_pool_cnn.name)\n",
    "\n",
    "if not os.path.exists(kaggle_2d_run_dir):\n",
    "    os.mkdir(kaggle_2d_run_dir)\n",
    "if os.path.exists(os.path.join(kaggle_2d_run_dir, 'logs')):\n",
    "    shutil.rmtree(os.path.join(kaggle_2d_run_dir, 'logs'))\n",
    "    \n",
    "#Feeding the models into a list will make the code more modular.\n",
    "models_to_train = [kaggle_2d_conv_pool_cnn, kaggle_1d_conv_pool_cnn]\n",
    "\n",
    "#Re-read the dataframes, as .jpg was appended to 'fname'\n",
    "traindf=pd.read_csv(traindf_dir)\n",
    "testdf=pd.read_csv(testdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for model in models_to_train:\n",
    "    print(f'+-----------Training {model.name} Model-----------+')\n",
    "    \n",
    "    if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "        kfold_validation = KFold(n_splits= number_of_splits, shuffle=True, random_state=kaggle_2d_seed)\n",
    "    elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "        kfold_validation = KFold(n_splits= number_of_splits, shuffle=True, random_state=kaggle_1d_seed)\n",
    "\n",
    "    # Although this makes the code looks ugly, it allows for better testability and repetibility\n",
    "    \n",
    "    run_dir = os.path.join('runs', model.name)\n",
    "    model_test_inputandlabels_file = os.path.join(run_dir, 'test_input_labels.npz')\n",
    "    \n",
    "    if not os.path.exists(model_test_inputandlabels_file) :\n",
    "        if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "            X_test, y_test = utils.create_mfcc_array(testdf, 'test', sr= kaggle_2d_sr, max_len= max_len, n_mfcc= n_mfcc)\n",
    "        elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "            X_test, y_test = utils.create_wav_array(testdf, 'test', sr= kaggle_1d_sr, max_len= max_len)\n",
    "        np.savez(model_test_inputandlabels_file, x_test=X_test, y_test=y_test)\n",
    "    if os.path.exists(model_test_inputandlabels_file):\n",
    "        arr = np.load(model_test_inputandlabels_file)\n",
    "        X_test, y_test = arr['x_test'], arr['y_test']\n",
    "        \n",
    "    #The models uses different input shapes\n",
    "    if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "        input_shape = utils.mfcc_input_sizes(n_mfcc, kaggle_2d_sr, max_len)\n",
    "        X_test= X_test.reshape(X_test.shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "    elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "        input_shape = utils.wav_input_sizes(kaggle_1d_sr, max_len)\n",
    "        X_test= X_test.reshape(X_test.shape[0], input_shape[0], input_shape[1])\n",
    "    \n",
    "    # Creating class matrix\n",
    "    y_test_hot = to_categorical(pd.Series(y_test).apply(lambda x: class_indices[x]))\n",
    "    \n",
    "    #Using random_state = 0 for repeatibility\n",
    "    for i, (train_split_indexes, test_split_indexes) in enumerate(kfold_validation.split(traindf)):\n",
    "        train_fold = traindf.iloc[train_split_indexes]\n",
    "        val_fold = traindf.iloc[test_split_indexes]\n",
    "        \n",
    "        model_inputandlabels_file = os.path.join(run_dir, f'fold{i}_input_labels.npz')\n",
    "        \n",
    "        #As as seed is used, splits should be consistent, allowing to store data to be reused, avoiding the lenghty generation of the needed arrays.\n",
    "        if not os.path.exists(model_inputandlabels_file):\n",
    "            #As the models use different inputs, it is necessary to diversify the X_train, y_train generation etc.\n",
    "            if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "                X_train, y_train = utils.create_mfcc_array(train_fold, 'train', sr= kaggle_2d_sr, max_len= max_len, n_mfcc= n_mfcc)\n",
    "                X_val, y_val = utils.create_mfcc_array(val_fold, 'train', sr= kaggle_2d_sr, max_len= max_len, n_mfcc= n_mfcc)\n",
    "            elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "                X_train, y_train = utils.create_wav_array(train_fold, 'train', sr= kaggle_1d_sr, max_len= max_len)\n",
    "                X_val, y_val = utils.create_wav_array(val_fold, 'train', sr= kaggle_1d_sr, max_len= max_len)\n",
    "            \n",
    "            np.savez(model_inputandlabels_file, x_train=X_train, y_train=y_train, x_val=X_val, y_val=y_val)\n",
    "\n",
    "        #Loading X_train and other necessary sets\n",
    "        if os.path.exists(model_inputandlabels_file):\n",
    "            arr = np.load(model_inputandlabels_file)\n",
    "            X_train, y_train = arr['x_train'], arr['y_train']\n",
    "            X_val, y_val = arr['x_val'], arr['y_val']\n",
    "        \n",
    "        best_weights_file = os.path.join(run_dir, f'best_{i}.h5')\n",
    "        checkpoint = ModelCheckpoint(best_weights_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "        tb = TensorBoard(log_dir= os.path.join(run_dir, 'logs', f'fold_{i}'), write_graph=True)\n",
    "    \n",
    "        callbacks_list = [checkpoint, early, tb]\n",
    "    \n",
    "        #Outputs are generated using consistend indices\n",
    "        y_train, y_val = pd.Series(y_train).apply(lambda x: class_indices[x]), pd.Series(y_val).apply(lambda x: class_indices[x])\n",
    "        \n",
    "        if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "            X_train, X_val = X_train.reshape(X_train.shape[0], input_shape[0], input_shape[1], input_shape[2]), X_val.reshape(X_val.shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "        elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "            X_train, X_val = X_train.reshape(X_train.shape[0], input_shape[0], input_shape[1]), X_val.reshape(X_val.shape[0], input_shape[0], input_shape[1])\n",
    "        \n",
    "        #Very important data normalization.\n",
    "        mean = np.mean(X_train, axis=0)\n",
    "        std = np.std(X_train, axis=0)\n",
    "        \n",
    "        #Normalizing sets using the X_train's values\n",
    "        X_train, X_val, X_test = (X_train - mean)/std\n",
    "        \n",
    "        y_train_hot = to_categorical(y_train)\n",
    "        y_val_hot = to_categorical(y_val)  \n",
    "        \n",
    "        model.fit(X_train, y_train_hot,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(X_val, y_val_hot),\n",
    "                    epochs=1)\n",
    "        \n",
    "        model.load_weights(best_weights_file)\n",
    "        \n",
    "        model.evaluate(X_test, y_test_hot)\n",
    "        \n",
    "        pred = model.predict(X_test, verbose= 1)\n",
    "    \n",
    "        np.save(os.path.join(run_dir, f'test_predictions_{i}.npy'), pred)\n",
    "        \n",
    "        pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the obtained metrics for each model\n",
    "\n",
    "for model in models_to_train:\n",
    "    pred_list = []\n",
    "    for i in range(number_of_splits):\n",
    "        pred_list.append(np.load(os.path.join(run_dir, f'test_predictions_{i}.npy')))\n",
    "    \n",
    "    prediction = np.ones_like(pred_list[0])\n",
    "    \n",
    "    for pred in pred_list:\n",
    "        prediction = prediction*pred\n",
    "    prediction = prediction**(1./len(pred_list))\n",
    "   \n",
    "    # Generate predictions\n",
    "    predicted_class_indices = np.argmax(prediction,axis=-1)\n",
    "    \n",
    "    labels = dict((v,k) for k,v in class_indices.items())\n",
    "    predicted_labels = [labels[k] for k in predicted_class_indices]\n",
    "    \n",
    "    test = pd.read_csv(testdf_dir)\n",
    "    test[['fname', 'label']].to_csv(os.path.join(run_dir, f'{model.name}_predictions.csv'), index=False)\n",
    "    \n",
    "    y_true = test['label']\n",
    "    y_pred = predicted_labels\n",
    "    \n",
    "    print(f'+-----------Printing {model.name} predictions evaluation-----------+')\n",
    "    print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Time to ensemple all of our model's predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling all the models using Geometric mean.\n",
    "pred_list = []\n",
    "for i in range(number_of_splits):\n",
    "    pred_list.append(np.load(os.path.join('runs', spectrogram_2d_conv_pool_cnn.name, f'test_predictions_{i}.npy')))\n",
    "    \n",
    "for model in models_to_train:\n",
    "    for i in range(number_of_splits):\n",
    "        pred_list.append(np.load(os.path.join('runs', model.name, f'test_predictions_{i}.npy')))\n",
    "\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "\n",
    "# Generate predictions\n",
    "\n",
    "predicted_class_indices = np.argmax(prediction,axis=-1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predicted_labels = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "test = pd.read_csv(testdf_dir)\n",
    "test[['fname', 'label']].to_csv(f'ensembled_predictions.csv', index=False)\n",
    "\n",
    "y_true = test['label']\n",
    "y_pred = predicted_labels\n",
    "\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "audio_tagging.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vvenv': conda)",
   "language": "python",
   "name": "python37764bitvvenvcondafa48b78b670947d8bc11c0248ea20194"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}