{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import audio_tagging_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Keras and other pre-processing libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "\n",
    "# This is needed to get if the gpu is detected, as we carried out runs on our local machines.\n",
    "# print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MSjOU2eBbUyR"
   },
   "source": [
    "A CNN within our project will be fed the spectrograms of the .wav as input images. Such images need to be generated first, this is carried out by calling a method defined in the utility file. Such method will fetch each .wav present in the input directory and traspose it to its corresponding spectrogram, saving it as a .jpg image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = os.path.join('images', 'train')\n",
    "test_path = os.path.join('images', 'test')\n",
    "\n",
    "if not os.path.exists(train_path):\n",
    "    os.mkdir(train_path)\n",
    "\n",
    "if not os.path.exists(test_path):\n",
    "    os.mkdir(test_path)\n",
    "\n",
    "if not len(glob(os.path.join(train_path, '*'))) == 9473:\n",
    "    utils.create_images('train', 'train')\n",
    "\n",
    "if not len(glob(os.path.join(test_path, '*'))) == 1600:\n",
    "    utils.create_images('test', 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dbMBfAgQJNTD"
   },
   "source": [
    "As the code aim to be highly modular, each employed model is defined as a method, this makes the Notebook more organic and readable, as each model is encapsulated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, LeakyReLU, Conv2D, MaxPooling2D, LSTM, Conv1D, MaxPooling1D, GlobalMaxPooling1D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "number_of_classes = 41\n",
    "\n",
    "def spectrogram_2d_conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu')(model_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x) #TO-FIX THIS\n",
    "\n",
    "    model = Model(model_input, x, name='spectrogram_2d_conv_pool_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def kaggle_2d_conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(model_input)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    \n",
    "    x = Conv2D(32, (4,10), padding=\"same\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(64)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='kaggle_2d_conv_pool_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def kaggle_1d_conv_pool_cnn(model_input: Tensor) -> training.Model:\n",
    "    x = Conv1D(16, 9, activation='relu', padding=\"valid\")(model_input)\n",
    "    x = Conv1D(16, 9, activation='relu', padding=\"valid\")(x)\n",
    "    x = MaxPooling1D(16)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = Conv1D(32, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = MaxPooling1D(4)(x)\n",
    "    x = Dropout(rate=0.1)(x)\n",
    "    \n",
    "    x = Conv1D(256, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = Conv1D(256, 3, activation='relu', padding=\"valid\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dropout(rate=0.2)(x)\n",
    "\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(1028, activation='relu')(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='kaggle_1d_conv_pool_cnn')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def cnn_lstm(model_input: Tensor) -> training.Model:\n",
    "    x = LSTM(512, activation='relu')(model_input)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dense(number_of_classes, activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='lstm')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to set up our trainining and evaluation pipeline for the model employing the .jpg spectrograms. The pipeline implement Kfold validation during training and evaluate each model on the test set, as well as generating its predictions using the best model obtained, as the best weights are saved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"spectrogram_2d_conv_pool_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 62, 62, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 31, 31, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 31, 31, 64)        36928     \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 29, 29, 64)        36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 14, 14, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 14, 14, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 128)       147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6, 6, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2359808   \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 41)                21033     \n",
      "=================================================================\n",
      "Total params: 2,695,529\n",
      "Trainable params: 2,695,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "number_of_splits = 5\n",
    "\n",
    "# Shape of the input to the CNN, this shape is obtained from the flow_from_dataset method implemented in the next cell.\n",
    "model_input = Input(shape=(64, 64, 3))\n",
    "spectrogram_2d_conv_pool_cnn = spectrogram_2d_conv_pool_cnn(model_input)\n",
    "spectrogram_2d_conv_pool_cnn.compile(optimizers.Adam(0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "spectrogram_2d_conv_pool_cnn.summary()\n",
    "\n",
    "# We generate a folder for each model, this allows for a clear separation of the runs. Allowing for a cleaner folder structure.\n",
    "\n",
    "run_dir = os.path.join('runs', spectrogram_2d_conv_pool_cnn.name)\n",
    "if not os.path.exists(run_dir):\n",
    "    os.mkdir(run_dir)\n",
    "if os.path.exists(os.path.join(run_dir, 'logs')):\n",
    "    shutil.rmtree(os.path.join(run_dir, 'logs'))\n",
    "    \n",
    "traindf_dir = os.path.join('meta', 'train.csv')\n",
    "testdf_dir = os.path.join('meta', 'test.csv')\n",
    "traindf=pd.read_csv(traindf_dir)\n",
    "testdf=pd.read_csv(testdf_dir)    \n",
    "\n",
    "# As the datasets have .wav, they need to be modified to search for .jpg files\n",
    "traindf[\"fname\"]= traindf[\"fname\"].apply(utils.append_ext)\n",
    "testdf[\"fname\"]= testdf[\"fname\"].apply(utils.append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------Training spectrogram_2d_conv_pool_cnn Model-----------+\n",
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "  1/236 [..............................] - ETA: 10:42WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
      "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: \n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": " Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node spectrogram_2d_conv_pool_cnn/conv2d/Conv2D (defined at <ipython-input-6-c910c5733d00>:58) ]] [Op:__inference_distributed_function_1578]\n\nFunction call stack:\ndistributed_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-c910c5733d00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     56\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m                     epochs=1)\n\u001b[0m\u001b[0;32m     59\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mspectrogram_2d_conv_pool_cnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_weights_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    630\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m     \u001b[0msix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m     keras_symbolic_tensors = [\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\six.py\u001b[0m in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "\u001b[1;31mUnknownError\u001b[0m:  Failed to get convolution algorithm. This is probably because cuDNN failed to initialize, so try looking to see if a warning log message was printed above.\n\t [[node spectrogram_2d_conv_pool_cnn/conv2d/Conv2D (defined at <ipython-input-6-c910c5733d00>:58) ]] [Op:__inference_distributed_function_1578]\n\nFunction call stack:\ndistributed_function\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Training con_pool_cnn\n",
    "\n",
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "# The class indices to encode the labels need to be static(if not, ensemble of predictiosn will not be correct)\n",
    "class_indices = {}\n",
    "\n",
    "kfold_validation = KFold(n_splits= number_of_splits, shuffle=True, random_state=0)\n",
    "\n",
    "# This structure is based on the one followed by the Kaggle notebook: https://www.kaggle.com/fizzbuzz/beginner-s-guide-to-audio-data\n",
    "#Using random_state = 0 for repeatibility\n",
    "print(f'+-----------Training {spectrogram_2d_conv_pool_cnn.name} Model-----------+')\n",
    "for i, (train_split_indexes, test_split_indexes) in enumerate(kfold_validation.split(traindf)):\n",
    "    train_fold = traindf.iloc[train_split_indexes]\n",
    "    val_fold = traindf.iloc[test_split_indexes]\n",
    "    \n",
    "    best_weights_file = os.path.join(run_dir, f'best_{i}.h5')\n",
    "    checkpoint = ModelCheckpoint(best_weights_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir= os.path.join(run_dir, 'logs', f'fold_{i}'), write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=train_fold,\n",
    "        directory=os.path.join('images', 'train'),\n",
    "        x_col=\"fname\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    valid_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=val_fold,\n",
    "        directory=os.path.join('images', 'train'),\n",
    "        x_col=\"fname\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "\n",
    "    spectrogram_2d_conv_pool_cnn.fit(train_generator,\n",
    "                    callbacks=callbacks_list,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=1)\n",
    "\n",
    "    spectrogram_2d_conv_pool_cnn.load_weights(best_weights_file)\n",
    "    \n",
    "    train_generator.reset()\n",
    "    valid_generator.reset()\n",
    "    \n",
    "    eval_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=testdf,\n",
    "        directory=os.path.join('images', 'test'),\n",
    "        x_col=\"fname\",\n",
    "        y_col= \"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    STEP_SIZE_EVAL=eval_generator.n//eval_generator.batch_size\n",
    "\n",
    "    # It is important to reset the generator before evaluation\n",
    "    eval_generator.reset()\n",
    "    \n",
    "    spectrogram_2d_conv_pool_cnn.evaluate(eval_generator, steps=STEP_SIZE_EVAL, verbose= 1)\n",
    "    \n",
    "    test_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=testdf,\n",
    "        directory=os.path.join('images', 'test'),\n",
    "        x_col=\"fname\",\n",
    "        y_col= None,\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=False,\n",
    "        class_mode= None,\n",
    "        target_size=(64,64))\n",
    "    \n",
    "    STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "    \n",
    "    test_generator.reset()\n",
    "    \n",
    "    pred = spectrogram_2d_conv_pool_cnn.predict(test_generator, steps=STEP_SIZE_TEST, verbose= 1)\n",
    "    \n",
    "    np.save(os.path.join(run_dir, f'test_predictions_{i}.npy'), pred)\n",
    "    \n",
    "    pd.DataFrame(spectrogram_2d_conv_pool_cnn.history.history).plot()\n",
    "    \n",
    "    #On last step, retrieve actual class_indices, this is used to retrieve the actual string labels\n",
    "    if i == number_of_splits - 1:\n",
    "        class_indices = train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "#Ensembling of the predictions\n",
    "pred_list = []\n",
    "for i in range(number_of_splits):\n",
    "    pred_list.append(np.load(os.path.join(run_dir, f'test_predictions_{i}.npy')))\n",
    "\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "\n",
    "#Saving predictions\n",
    "predicted_class_indices = np.argmax(prediction,axis=-1)\n",
    "\n",
    "labels = dict((v,k) for k,v in class_indices.items())\n",
    "predicted_labels = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "test = pd.read_csv(testdf_dir)\n",
    "\n",
    "test[['fname', 'label']].to_csv(os.path.join(run_dir, f'{spectrogram_2d_conv_pool_cnn.name}_predictions.csv'), index=False)\n",
    "\n",
    "y_true = test['label']\n",
    "y_pred = predicted_labels\n",
    "\n",
    "print(f'+-----------Printing {spectrogram_2d_conv_pool_cnn.name} predictions evaluations-----------+')\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D8cFBm1fJFe5"
   },
   "source": [
    "Now we will train a different model that uses raw mfcc obtained from the .wav files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 2\n",
    "n_mfcc = 40\n",
    "\n",
    "#raw .wav and mfcc are obtained using different sample rates, we followed the values used on the Kaggle notebook previously cited.\n",
    "kaggle_2d_sr = 44100\n",
    "kaggle_1d_sr = 16000\n",
    "\n",
    "kaggle_2d_seed = 2\n",
    "kaggle_1d_seed = 1\n",
    "\n",
    "model_input = Input(shape=utils.mfcc_input_sizes(n_mfcc, kaggle_2d_sr, max_len))\n",
    "kaggle_2d_conv_pool_cnn = kaggle_2d_conv_pool_cnn(model_input) \n",
    "kaggle_2d_conv_pool_cnn.compile(optimizers.Adam(0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "model_input = Input(shape=utils.wav_input_sizes(kaggle_1d_sr, max_len))\n",
    "kaggle_1d_conv_pool_cnn = kaggle_1d_conv_pool_cnn(model_input) \n",
    "kaggle_1d_conv_pool_cnn.compile(optimizers.Adam(0.0001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "\n",
    "kaggle_1d_run_dir = os.path.join('runs', kaggle_1d_conv_pool_cnn.name)\n",
    "\n",
    "if not os.path.exists(kaggle_1d_run_dir):\n",
    "    os.mkdir(kaggle_1d_run_dir)\n",
    "if os.path.exists(os.path.join(kaggle_1d_run_dir, 'logs')):\n",
    "    shutil.rmtree(os.path.join(kaggle_1d_run_dir, 'logs'))\n",
    "    \n",
    "kaggle_2d_run_dir = os.path.join('runs', kaggle_2d_conv_pool_cnn.name)\n",
    "\n",
    "if not os.path.exists(kaggle_2d_run_dir):\n",
    "    os.mkdir(kaggle_2d_run_dir)\n",
    "if os.path.exists(os.path.join(kaggle_2d_run_dir, 'logs')):\n",
    "    shutil.rmtree(os.path.join(kaggle_2d_run_dir, 'logs'))\n",
    "    \n",
    "#Feeding the models into a list will make the code more modular.\n",
    "models_to_train = [kaggle_2d_conv_pool_cnn, kaggle_1d_conv_pool_cnn]\n",
    "\n",
    "#Re-read the dataframes, as .jpg was appended to 'fname'\n",
    "traindf=pd.read_csv(traindf_dir)\n",
    "testdf=pd.read_csv(testdf_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "for model in models_to_train:\n",
    "    print(f'+-----------Training {model.name} Model-----------+')\n",
    "    \n",
    "    if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "        kfold_validation = KFold(n_splits= number_of_splits, shuffle=True, random_state=kaggle_2d_seed)\n",
    "    elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "        kfold_validation = KFold(n_splits= number_of_splits, shuffle=True, random_state=kaggle_1d_seed)\n",
    "\n",
    "    # Although this makes the code looks ugly, it allows for better testability and repetibility\n",
    "    \n",
    "    run_dir = os.path.join('runs', model.name)\n",
    "    model_test_inputandlabels_file = os.path.join(run_dir, 'test_input_labels.npz')\n",
    "    \n",
    "    if not os.path.exists(model_inputandlabels_file) :\n",
    "        if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "            X_test, y_test = utils.create_mfcc_array(testdf, 'test', sr= kaggle_2d_sr, max_len= max_len, n_mfcc= n_mfcc)\n",
    "        elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "            X_test, y_test = utils.create_wav_array(testdf, 'test', sr= kaggle_1d_sr, max_len= max_len)\n",
    "        np.savez(model_inputandlabels_file, x_test=X_test, y_test=y_test)\n",
    "    if os.path.exists(model_inputandlabels_file):\n",
    "        arr = np.load(model_inputandlabels_file)\n",
    "        X_test, y_test = arr['x_test'], arr['y_test']\n",
    "        \n",
    "    if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "        input_shape = utils.mfcc_input_sizes(n_mfcc, kaggle_2d_sr, max_len)\n",
    "        X_test= X_test.reshape(X_test.shape[0], input_shape[0], input_shape[1], input_shape[2])#, input_shape[2])\n",
    "    elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "        input_shape = utils.wav_input_sizes(kaggle_1d_sr, max_len)\n",
    "        X_test= X_test.reshape(X_test.shape[0], input_shape[0], input_shape[1])#, input_shape[2])\n",
    "    \n",
    "    y_test_hot = to_categorical(pd.Series(y_test).apply(lambda x: class_indices[x]))\n",
    "    \n",
    "    mean = np.mean(X_test, axis=0)\n",
    "    std = np.std(X_test, axis=0)\n",
    "        \n",
    "    X_test = (X_test - mean)/std\n",
    "    \n",
    "    #Using random_state = 0 for repeatibility\n",
    "    for i, (train_split_indexes, test_split_indexes) in enumerate(kfold_validation.split(traindf)):\n",
    "        train_fold = traindf.iloc[train_split_indexes]\n",
    "        val_fold = traindf.iloc[test_split_indexes]\n",
    "        \n",
    "        model_fold_inputandlabels_file = os.path.join(run_dir, f'fold{i}_input_labels.npz')\n",
    "        \n",
    "        #As as seed is used, splits should be consistent, allowing to store data to be reused, avoiding the lenghty generation of the needed arrays.\n",
    "        if not os.path.exists(model_fold_inputandlabels_file):\n",
    "            \n",
    "            #As the models use different inputs, it is necessary to diversify the X_train, y_train generation etc.\n",
    "            if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "                X_train, y_train = utils.create_mfcc_array(train_fold, 'train', sr= kaggle_2d_sr, max_len= max_len, n_mfcc= n_mfcc)\n",
    "                X_val, y_val = utils.create_mfcc_array(val_fold, 'train', sr= kaggle_2d_sr, max_len= max_len, n_mfcc= n_mfcc)\n",
    "            elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "                X_train, y_train = utils.create_wav_array(train_fold, 'train', sr= kaggle_1d_sr, max_len= max_len)\n",
    "                X_val, y_val = utils.create_wav_array(val_fold, 'train', sr= kaggle_1d_sr, max_len= max_len)\n",
    "            \n",
    "            np.savez(model_fold_inputandlabels_file, x_train=X_train, y_train=y_train, x_val=X_val, y_val=y_val)\n",
    "        if os.path.exists(model_fold_inputandlabels_file):\n",
    "            arr = np.load(model_fold_inputandlabels_file)\n",
    "            X_train, y_train = arr['x_train'], arr['y_train']\n",
    "            X_val, y_val = arr['x_val'], arr['y_val']\n",
    "        \n",
    "        best_weights_file = os.path.join(run_dir, f'best_{i}.h5')\n",
    "        checkpoint = ModelCheckpoint(best_weights_file, monitor='val_loss', verbose=1, save_best_only=True)\n",
    "        early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "        tb = TensorBoard(log_dir= os.path.join(run_dir, 'logs', f'fold_{i}'), write_graph=True)\n",
    "    \n",
    "        callbacks_list = [checkpoint, early, tb]\n",
    "    \n",
    "        #Outputs are generated using consistend indices\n",
    "        y_train, y_val = pd.Series(y_train).apply(lambda x: class_indices[x]), pd.Series(y_val).apply(lambda x: class_indices[x])\n",
    "        \n",
    "        if model.name == 'kaggle_2d_conv_pool_cnn':\n",
    "            X_train, X_val = X_train.reshape(X_train.shape[0], input_shape[0], input_shape[1], input_shape[2]), X_val.reshape(X_val.shape[0], input_shape[0], input_shape[1], input_shape[2])\n",
    "        elif model.name == 'kaggle_1d_conv_pool_cnn':\n",
    "            X_train, X_val = X_train.reshape(X_train.shape[0], input_shape[0], input_shape[1]), X_val.reshape(X_val.shape[0], input_shape[0], input_shape[1])\n",
    "        \n",
    "        #Very important data normalization.\n",
    "        mean = np.mean(X_train, axis=0)\n",
    "        std = np.std(X_train, axis=0)\n",
    "        \n",
    "        X_train, X_val = (X_train - mean)/std, (X_val - mean)/std\n",
    "        \n",
    "        y_train_hot = to_categorical(y_train)\n",
    "        y_val_hot = to_categorical(y_val)  \n",
    "        \n",
    "        model.fit(X_train, y_train_hot,\n",
    "                    callbacks=callbacks_list,\n",
    "                    validation_data=(X_val, y_val_hot),\n",
    "                    epochs=1)\n",
    "        \n",
    "        model.load_weights(best_weights_file)\n",
    "        \n",
    "        model.evaluate(X_test, y_test_hot)\n",
    "        \n",
    "        pred = model.predict(X_test, verbose= 1)\n",
    "    \n",
    "        np.save(os.path.join(run_dir, f'test_predictions_{i}.npy'), pred)\n",
    "        \n",
    "        pd.DataFrame(model.history.history).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Showing the obtained metrics for each model\n",
    "\n",
    "for model in models_to_train:\n",
    "    pred_list = []\n",
    "    for i in range(number_of_splits):\n",
    "        pred_list.append(np.load(os.path.join(run_dir, f'test_predictions_{i}.npy')))\n",
    "    \n",
    "    prediction = np.ones_like(pred_list[0])\n",
    "    \n",
    "    for pred in pred_list:\n",
    "        prediction = prediction*pred\n",
    "    prediction = prediction**(1./len(pred_list))\n",
    "    # Make a submission file\n",
    "    \n",
    "    predicted_class_indices = np.argmax(prediction,axis=-1)\n",
    "    \n",
    "    labels = dict((v,k) for k,v in class_indices.items())\n",
    "    predicted_labels = [labels[k] for k in predicted_class_indices]\n",
    "    \n",
    "    test = pd.read_csv(testdf_dir)\n",
    "    test[['fname', 'label']].to_csv(os.path.join(run_dir, f'{model.name}_predictions.csv'), index=False)\n",
    "    \n",
    "    y_true = test['label']\n",
    "    y_pred = predicted_labels\n",
    "    \n",
    "    print(f'+-----------Printing {model.name} predictions evaluation-----------+')\n",
    "    print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to ensemple our predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensembling all the models using Geometric mean averaging.\n",
    "\n",
    "pred_list = []\n",
    "for i in range(number_of_splits):\n",
    "    pred_list.append(np.load(os.path.join('runs', {spectrogram_2d_conv_pool_cnn.name} ,f'test_predictions_{i}.npy')))\n",
    "    \n",
    "for model in models_to_train:\n",
    "    for i in range(number_of_splits):\n",
    "        pred_list.append(np.load(os.path.join('runs', {model.name} ,f'test_predictions_{i}.npy')))\n",
    "\n",
    "prediction = np.ones_like(pred_list[0])\n",
    "\n",
    "for pred in pred_list:\n",
    "    prediction = prediction*pred\n",
    "prediction = prediction**(1./len(pred_list))\n",
    "\n",
    "# Generate predictions\n",
    "\n",
    "predicted_class_indices = np.argmax(prediction,axis=-1)\n",
    "labels = (train_generator.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predicted_labels = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "test = pd.read_csv(testdf_dir)\n",
    "test[['fname', 'label']].to_csv(f'ensembled_predictions.csv', index=False)\n",
    "\n",
    "y_true = test['label']\n",
    "y_pred = predicted_labels\n",
    "\n",
    "print(metrics.classification_report(y_true, y_pred, digits=3))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "audio_tagging.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv': conda)",
   "language": "python",
   "name": "python37764bitvenvcondaddcca5ddd0864716aff268d03a1bc27f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
