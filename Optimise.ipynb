{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import audio_tagging_utils as utils\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from tensorflow.keras.layers import Input\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, LeakyReLU, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTION_FOLDER = \"conv_pool_cnn_no_prepro\"\n",
    "if not os.path.exists(f'runs/{PREDICTION_FOLDER}'):\n",
    "    os.mkdir(f'runs/{PREDICTION_FOLDER}')\n",
    "if os.path.exists(f'runs/{PREDICTION_FOLDER}/logs'):\n",
    "    shutil.rmtree(f'runs/{PREDICTION_FOLDER}/logs')\n",
    "\n",
    "traindf=pd.read_csv('meta/train.csv')\n",
    "testdf=pd.read_csv('meta/test.csv')\n",
    "traindf[\"fname\"]= traindf[\"fname\"].apply(utils.append_ext)\n",
    "testdf[\"fname\"]= testdf[\"fname\"].apply(utils.append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "1\n",
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "2\n",
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "3\n",
      "Found 7579 validated image filenames belonging to 41 classes.\n",
      "Found 1894 validated image filenames belonging to 41 classes.\n",
      "4\n",
      "Found 7579 validated image filenames belonging to 41 classes.\n",
      "Found 1894 validated image filenames belonging to 41 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "class_indices = {}\n",
    "\n",
    "number_of_splits = 5\n",
    "\n",
    "kfold_validation = KFold(n_splits = number_of_splits)\n",
    "\n",
    "for i, (train_split_indexes, test_split_indexes) in enumerate(kfold_validation.split(traindf)):\n",
    "    train_fold = traindf.iloc[train_split_indexes]\n",
    "    val_fold = traindf.iloc[test_split_indexes]\n",
    "    print(i)\n",
    "    checkpoint = ModelCheckpoint(f'runs/{PREDICTION_FOLDER}/best_{i}.h5', monitor='val_loss', verbose=1, save_best_only=True)\n",
    "    early = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "    tb = TensorBoard(log_dir=f'runs/{PREDICTION_FOLDER}/logs/fold_{i}', write_graph=True)\n",
    "\n",
    "    callbacks_list = [checkpoint, early, tb]\n",
    "\n",
    "    train_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=train_fold,\n",
    "        directory=\"images/train_no_preprocessing/\",\n",
    "        x_col=\"fname\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    valid_generator=datagen.flow_from_dataframe(\n",
    "        dataframe=val_fold,\n",
    "        directory=\"images/train_no_preprocessing/\",\n",
    "        x_col=\"fname\",\n",
    "        y_col=\"label\",\n",
    "        batch_size=32,\n",
    "        seed=42,\n",
    "        shuffle=True,\n",
    "        class_mode=\"categorical\",\n",
    "        target_size=(64,64))\n",
    "\n",
    "    STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "    STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_pool_cnn(model_input: Tensor, params: dict) -> training.Model:\n",
    "    x = Conv2D(32, (3, 3), padding='same')(model_input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(params[\"dropouts\"][0])(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(params[\"dropouts\"][1])(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(params[\"dropouts\"][2])(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(params[\"dropouts\"][3])(x)\n",
    "    x = Dense(41, activation='softmax')(x)\n",
    "\n",
    "    model = Model(model_input, x, name='conv_pool_cnn')\n",
    "    model.compile(optimizers.Adam(params[\"lr\"][0]),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimising LR, LR = 1.0\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 60ms/step - loss: 34398172444965.9531 - accuracy: 0.0290 - val_loss: 3.9100 - val_accuracy: 0.0350\n",
      "\n",
      "validation accuracy for this run is: 0.03495763 and highest accuracy achieved is: 0.034957628697156906\n",
      "\n",
      "Optimising LR, LR = 0.1\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 55ms/step - loss: 3.8713 - accuracy: 0.0276 - val_loss: 3.8761 - val_accuracy: 0.0281\n",
      "\n",
      "validation accuracy for this run is: 0.028072033 and highest accuracy achieved is: 0.034957628697156906\n",
      "\n",
      "Optimising LR, LR = 0.010000000000000002\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 56ms/step - loss: 346417516.7130 - accuracy: 0.0278 - val_loss: 5.4415 - val_accuracy: 0.0254\n",
      "\n",
      "validation accuracy for this run is: 0.025423728 and highest accuracy achieved is: 0.034957628697156906\n",
      "\n",
      "Optimising LR, LR = 0.0010000000000000002\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 55ms/step - loss: 373658649.4450 - accuracy: 0.0262 - val_loss: 3.9351 - val_accuracy: 0.0318\n",
      "\n",
      "validation accuracy for this run is: 0.03177966 and highest accuracy achieved is: 0.034957628697156906\n",
      "\n",
      "Optimising LR, LR = 0.00010000000000000003\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 3.8774 - accuracy: 0.0252 - val_loss: 3.8502 - val_accuracy: 0.0328\n",
      "\n",
      "validation accuracy for this run is: 0.03283898 and highest accuracy achieved is: 0.034957628697156906\n",
      "\n",
      "\n",
      "Optimising layer 0 Droupout\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 59ms/step - loss: 543815225.4733 - accuracy: 0.0297 - val_loss: 3.8192 - val_accuracy: 0.0312\n",
      "\n",
      "validation accuracy for this run is: 0.03125 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 57ms/step - loss: 3.8667 - accuracy: 0.0298 - val_loss: 3.9237 - val_accuracy: 0.0307\n",
      "\n",
      "validation accuracy for this run is: 0.030720338 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 57ms/step - loss: 55892319.1667 - accuracy: 0.0293 - val_loss: 3.8700 - val_accuracy: 0.0307\n",
      "\n",
      "validation accuracy for this run is: 0.030720338 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 3.8913 - accuracy: 0.0293 - val_loss: 3.8750 - val_accuracy: 0.0254\n",
      "\n",
      "validation accuracy for this run is: 0.025423728 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 56ms/step - loss: 191071840.2213 - accuracy: 0.0273 - val_loss: 3.8800 - val_accuracy: 0.0196\n",
      "\n",
      "validation accuracy for this run is: 0.019597458 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 59ms/step - loss: 3.8816 - accuracy: 0.0298 - val_loss: 3.7975 - val_accuracy: 0.0281\n",
      "\n",
      "validation accuracy for this run is: 0.028072033 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 57ms/step - loss: 3.8947 - accuracy: 0.0333 - val_loss: 3.9562 - val_accuracy: 0.0286\n",
      "\n",
      "validation accuracy for this run is: 0.028601695 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 3.9230 - accuracy: 0.0268 - val_loss: 3.8945 - val_accuracy: 0.0281\n",
      "\n",
      "validation accuracy for this run is: 0.028072033 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 3.9106 - accuracy: 0.0305 - val_loss: 3.8995 - val_accuracy: 0.0297\n",
      "\n",
      "validation accuracy for this run is: 0.029661017 and highest accuracy achieved is: 0.03125\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 3.9085 - accuracy: 0.0306 - val_loss: 3.9342 - val_accuracy: 0.0360\n",
      "\n",
      "validation accuracy for this run is: 0.03601695 and highest accuracy achieved is: 0.03601694852113724\n",
      "\n",
      "\n",
      "Optimising layer 1 Droupout\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 57ms/step - loss: 3.8962 - accuracy: 0.0288 - val_loss: 3.9397 - val_accuracy: 0.0307\n",
      "\n",
      "validation accuracy for this run is: 0.030720338 and highest accuracy achieved is: 0.030720338225364685\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 57ms/step - loss: 3.8816 - accuracy: 0.0289 - val_loss: 3.9699 - val_accuracy: 0.0339\n",
      "\n",
      "validation accuracy for this run is: 0.033898305 and highest accuracy achieved is: 0.033898305147886276\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 13s 57ms/step - loss: 3.9147 - accuracy: 0.0290 - val_loss: 3.8223 - val_accuracy: 0.0344\n",
      "\n",
      "validation accuracy for this run is: 0.034427967 and highest accuracy achieved is: 0.03442796692252159\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 3.9037 - accuracy: 0.0325 - val_loss: 3.9436 - val_accuracy: 0.0334\n",
      "\n",
      "validation accuracy for this run is: 0.033368643 and highest accuracy achieved is: 0.03442796692252159\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "234/236 [============================>.] - ETA: 0s - loss: 3.9108 - accuracy: 0.0283 ETA: 1s -"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6088f3dfbec5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     61\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalid_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSTEP_SIZE_VALID\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                         epochs=1)\n\u001b[0m\u001b[0;32m     64\u001b[0m         \u001b[1;31m#Collect the validation accuracyS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 819\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    820\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    340\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 342\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    343\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    126\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    127\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     97\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 98\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     99\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    100\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    566\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    597\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2361\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2362\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2363\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2365\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1609\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1610\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1611\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1612\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1613\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1690\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1692\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1693\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1694\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    543\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 545\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    546\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    547\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\tools\\Anaconda3\\envs\\venv\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=(64, 64, 3))\n",
    "\n",
    "#Initialise the parameters\n",
    "params = {} \n",
    "params[\"dropouts\"] = [0.5, 0.5, 0.5, 0.5] \n",
    "params[\"lr\"] = [1.0]\n",
    "\n",
    "conv_pool_cnn_model = conv_pool_cnn(model_input, params)\n",
    "\n",
    "#Set Arbitrary placeholder variables\n",
    "val_acc_max = 0\n",
    "opt_dropout = 1\n",
    "opt_lr = 10\n",
    "\n",
    "\n",
    "#Optimise Learning Rate\n",
    "while float(params[\"lr\"][0]) > 0.0001:\n",
    "    \n",
    "    print('Optimising LR, LR = ' + str(params[\"lr\"][0]) + '\\n')\n",
    "    \n",
    "    #Fit the training data with one epoch\n",
    "    optimise = conv_pool_cnn_model.fit(train_generator,\n",
    "                steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                validation_data=valid_generator,\n",
    "                validation_steps=STEP_SIZE_VALID,\n",
    "                epochs=1)\n",
    "    \n",
    "    #Collect the validation accuracy\n",
    "    val_acc = optimise.history['val_accuracy']\n",
    "    \n",
    "    #Check if the validation accuracy is higher than the current best\n",
    "    if float(val_acc[0]) > val_acc_max:\n",
    "        \n",
    "        #Update placeholders with the highest validation accuracy achieved\n",
    "        #And the learning rate that achieved this\n",
    "        val_acc_max = float(val_acc[0])\n",
    "        opt_lr = params[\"lr\"][0]\n",
    "    \n",
    "    print('\\nvalidation accuracy for this run is: ' + str(val_acc[0]) + ' and highest accuracy achieved is: ' + str(val_acc_max) + '\\n')\n",
    "    #Update the learning rate to the next test sample\n",
    "    params[\"lr\"][0] *= 0.1\n",
    "\n",
    "#Set the learning rate to the optimised value\n",
    "params[\"lr\"][0] = opt_lr\n",
    "\n",
    "\n",
    "#Optimise Dropouts, for loop sets which layer we are optimising for\n",
    "for i in range(0, len(params[\"dropouts\"])):\n",
    "    \n",
    "    print('\\nOptimising layer ' + str(i) + ' Droupout\\n')\n",
    "    \n",
    "    #Set Arbitrary placeholder variables\n",
    "    val_acc_max = 0\n",
    "    opt_dropout = 1\n",
    "\n",
    "    #Fit the training data with one epoch\n",
    "    while params[\"dropouts\"][i] > 0.05:\n",
    "\n",
    "        optimise = conv_pool_cnn_model.fit(train_generator,\n",
    "                        steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                        validation_data=valid_generator,\n",
    "                        validation_steps=STEP_SIZE_VALID,\n",
    "                        epochs=1)\n",
    "        #Collect the validation accuracyS\n",
    "        \n",
    "        val_acc = optimise.history['val_accuracy']\n",
    "    \n",
    "        #Check if the validation accuracy is higher than the current best\n",
    "        if float(val_acc[0]) > val_acc_max:\n",
    "            \n",
    "            #Update placeholders with the highest validation accuracy achieved\n",
    "            #And the dropout that achieved this\n",
    "            val_acc_max = float(val_acc[0])\n",
    "            opt_dropout = params[\"dropouts\"][i]\n",
    "        \n",
    "        print('\\nvalidation accuracy for this run is: ' + str(val_acc[0]) + ' and highest accuracy achieved is: ' + str(val_acc_max) + '\\n')\n",
    "        #Update the dropout to the next test sample\n",
    "        params[\"dropouts\"][i] -= 0.05\n",
    "    \n",
    "    #Set the dropout to the optimised value\n",
    "    params[\"dropouts\"][i] = opt_dropout\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('venv': conda)",
   "language": "python",
   "name": "python37764bitvenvcondaddcca5ddd0864716aff268d03a1bc27f"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
