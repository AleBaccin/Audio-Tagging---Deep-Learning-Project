{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.backend as K\n",
    "import gc\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras import layers, models, regularizers, optimizers\n",
    "from tensorflow.python.keras.engine import training\n",
    "from tensorflow.python.framework.ops import Tensor\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization, LeakyReLU, Conv2D, MaxPooling2D, LSTM\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "import optimise_util as opt\n",
    "import audio_tagging_utils as utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "traindf=pd.read_csv(os.path.join('meta', 'train.csv'))\n",
    "testdf=pd.read_csv(os.path.join('meta', 'test.csv'))\n",
    "traindf[\"fname\"]= traindf[\"fname\"].apply(utils.append_ext)\n",
    "testdf[\"fname\"]= testdf[\"fname\"].apply(utils.append_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kaggle_2d_conv_pool_cnn(model_input: Tensor, params: dict) -> training.Model:\n",
    "    x = Conv2D(32, (3, 3), padding='same')(model_input)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(params[\"dropouts\"][0])(x)\n",
    "    \n",
    "    x = Conv2D(64, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(64, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(params[\"dropouts\"][1])(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Conv2D(128, (3, 3))(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(params[\"dropouts\"][2])(x)\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(params[\"dropouts\"][3])(x)\n",
    "    x = Dense(41, activation='softmax')(x)\n",
    "\n",
    "    model = Model(model_input, x, name='conv_pool_cnn')\n",
    "    model.compile(optimizers.Adam(params[\"lr\"][0]),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "Found 7578 validated image filenames belonging to 41 classes.\n",
      "Found 1895 validated image filenames belonging to 41 classes.\n",
      "Found 7579 validated image filenames belonging to 41 classes.\n",
      "Found 1894 validated image filenames belonging to 41 classes.\n",
      "Found 7579 validated image filenames belonging to 41 classes.\n",
      "Found 1894 validated image filenames belonging to 41 classes.\n",
      "Optimising LR, LR = 0.001\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 18s 77ms/step - loss: 3.0430 - accuracy: 0.1651 - val_loss: 2.3846 - val_accuracy: 0.3083\n",
      "\n",
      "validation accuracy for this run is: 0.3082627 and highest accuracy achieved is: 0.3082627058029175\n",
      "\n",
      "Optimising layer 0 droupout, dropout = 0.1\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 2.1349 - accuracy: 0.4008 - val_loss: 1.8931 - val_accuracy: 0.4899\n",
      "\n",
      "validation accuracy for this run is: 0.48993644 and highest accuracy achieved is: 0.4899364411830902\n",
      "\n",
      "Optimising layer 1 droupout, dropout = 0.1\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 12s 52ms/step - loss: 1.6509 - accuracy: 0.5327 - val_loss: 1.5765 - val_accuracy: 0.5620\n",
      "\n",
      "validation accuracy for this run is: 0.56197035 and highest accuracy achieved is: 0.5619703531265259\n",
      "\n",
      "Optimising layer 2 droupout, dropout = 0.1\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 58ms/step - loss: 1.3414 - accuracy: 0.6155 - val_loss: 1.4946 - val_accuracy: 0.5805\n",
      "\n",
      "validation accuracy for this run is: 0.5805085 and highest accuracy achieved is: 0.5805084705352783\n",
      "\n",
      "Optimising layer 3 droupout, dropout = 0.1\n",
      "\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 236 steps, validate for 59 steps\n",
      "236/236 [==============================] - 14s 60ms/step - loss: 1.1412 - accuracy: 0.6673 - val_loss: 1.4528 - val_accuracy: 0.6197\n",
      "\n",
      "validation accuracy for this run is: 0.6197034 and highest accuracy achieved is: 0.6197034120559692\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_input = Input(shape=(64, 64, 3))\n",
    "\n",
    "#Initialise the parameters\n",
    "params = {} \n",
    "params[\"dropouts\"] = [0.1, 0.1, 0.1, 0.1] \n",
    "params[\"lr\"] = [0.001]\n",
    "\n",
    "kaggle_2d_model = kaggle_2d_conv_pool_cnn(model_input, params)\n",
    "\n",
    "#Calls utilities file, returns doct of optimised parameters\n",
    "params = opt.optimise(kaggle_2d_model, traindf, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dropouts': [0.1, 0.1, 0.1, 0.1], 'lr': [0.001]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('vvenv': conda)",
   "language": "python",
   "name": "python37764bitvvenvcondafa48b78b670947d8bc11c0248ea20194"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
